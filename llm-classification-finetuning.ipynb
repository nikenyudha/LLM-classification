{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:23.650979Z","iopub.execute_input":"2025-09-24T03:03:23.651554Z","iopub.status.idle":"2025-09-24T03:03:24.052847Z","shell.execute_reply.started":"2025-09-24T03:03:23.651520Z","shell.execute_reply":"2025-09-24T03:03:24.051113Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:28.123489Z","iopub.execute_input":"2025-09-24T03:03:28.124289Z","iopub.status.idle":"2025-09-24T03:03:29.467549Z","shell.execute_reply.started":"2025-09-24T03:03:28.124240Z","shell.execute_reply":"2025-09-24T03:03:29.466601Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:29.469076Z","iopub.execute_input":"2025-09-24T03:03:29.469600Z","iopub.status.idle":"2025-09-24T03:03:34.055111Z","shell.execute_reply.started":"2025-09-24T03:03:29.469566Z","shell.execute_reply":"2025-09-24T03:03:34.054183Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:34.055990Z","iopub.execute_input":"2025-09-24T03:03:34.056372Z","iopub.status.idle":"2025-09-24T03:03:34.088238Z","shell.execute_reply.started":"2025-09-24T03:03:34.056348Z","shell.execute_reply":"2025-09-24T03:03:34.087040Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      id             model_a     model_b  \\\n0  30192  gpt-4-1106-preview  gpt-4-0613   \n1  53567           koala-13b  gpt-4-0613   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:34.089888Z","iopub.execute_input":"2025-09-24T03:03:34.090295Z","iopub.status.idle":"2025-09-24T03:03:34.112304Z","shell.execute_reply.started":"2025-09-24T03:03:34.090267Z","shell.execute_reply":"2025-09-24T03:03:34.111036Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       id                                             prompt  \\\n0  136060  [\"I have three oranges today, I ate an orange ...   \n1  211333  [\"You are a mediator in a heated political deb...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:36.116158Z","iopub.execute_input":"2025-09-24T03:03:36.116553Z","iopub.status.idle":"2025-09-24T03:03:36.172921Z","shell.execute_reply.started":"2025-09-24T03:03:36.116527Z","shell.execute_reply":"2025-09-24T03:03:36.171816Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:36.619293Z","iopub.execute_input":"2025-09-24T03:03:36.619627Z","iopub.status.idle":"2025-09-24T03:03:36.633637Z","shell.execute_reply.started":"2025-09-24T03:03:36.619596Z","shell.execute_reply":"2025-09-24T03:03:36.632307Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3 entries, 0 to 2\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   id          3 non-null      int64 \n 1   prompt      3 non-null      object\n 2   response_a  3 non-null      object\n 3   response_b  3 non-null      object\ndtypes: int64(1), object(3)\nmemory usage: 228.0+ bytes\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#EDA\nprint(\"Mean winner_model_a:\", train[\"winner_model_a\"].mean())\nprint(\"Mean winner_model_b:\", train[\"winner_model_b\"].mean())\nprint(\"Mean winner_tie:\", train[\"winner_tie\"].mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:37.363090Z","iopub.execute_input":"2025-09-24T03:03:37.363449Z","iopub.status.idle":"2025-09-24T03:03:37.370744Z","shell.execute_reply.started":"2025-09-24T03:03:37.363423Z","shell.execute_reply":"2025-09-24T03:03:37.369715Z"}},"outputs":[{"name":"stdout","text":"Mean winner_model_a: 0.34907876193955845\nMean winner_model_b: 0.341910677314404\nMean winner_tie: 0.30901056074603755\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(\"Std winner_model_a:\", train[\"winner_model_a\"].std())\nprint(\"Std winner_model_b:\", train[\"winner_model_b\"].std())\nprint(\"Std winner_tie:\", train[\"winner_tie\"].std())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:03:37.638753Z","iopub.execute_input":"2025-09-24T03:03:37.639085Z","iopub.status.idle":"2025-09-24T03:03:37.646554Z","shell.execute_reply.started":"2025-09-24T03:03:37.639061Z","shell.execute_reply":"2025-09-24T03:03:37.645548Z"}},"outputs":[{"name":"stdout","text":"Std winner_model_a: 0.47668305324710053\nStd winner_model_b: 0.4743539615785192\nStd winner_tie: 0.46208954661193535\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Count model_a\nwin_a = train.groupby(\"model_a\")[\"winner_model_a\"].mean()\n\n# Count model_b\nwin_b = train.groupby(\"model_b\")[\"winner_model_b\"].mean()\n\n# Concat\nmodel_winrate = pd.concat([win_a, win_b], axis=1).fillna(0)\nmodel_winrate.columns = [\"win_as_A\", \"win_as_B\"]\n\n# total winrate\nmodel_winrate[\"total_winrate\"] = (model_winrate[\"win_as_A\"] + model_winrate[\"win_as_B\"]) / 2\nmodel_winrate.sort_values(\"total_winrate\", ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:22.805265Z","iopub.execute_input":"2025-09-24T03:06:22.805899Z","iopub.status.idle":"2025-09-24T03:06:22.833511Z","shell.execute_reply.started":"2025-09-24T03:06:22.805873Z","shell.execute_reply":"2025-09-24T03:06:22.832530Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                         win_as_A  win_as_B  total_winrate\ngpt-4-1106-preview       0.548940  0.553788       0.551364\ngpt-3.5-turbo-0314       0.568111  0.524390       0.546251\ngpt-4-0125-preview       0.525573  0.502530       0.514051\ngpt-4-0314               0.494969  0.471744       0.483357\nclaude-1                 0.443478  0.434998       0.439238\n...                           ...       ...            ...\nstablelm-tuned-alpha-7b  0.175127  0.167109       0.171118\nllama-13b                0.154676  0.167286       0.160981\nchatglm3-6b              0.166998  0.150206       0.158602\ndolly-v2-12b             0.161209  0.148883       0.155046\nchatglm2-6b              0.123675  0.135231       0.129453\n\n[64 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>win_as_A</th>\n      <th>win_as_B</th>\n      <th>total_winrate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gpt-4-1106-preview</th>\n      <td>0.548940</td>\n      <td>0.553788</td>\n      <td>0.551364</td>\n    </tr>\n    <tr>\n      <th>gpt-3.5-turbo-0314</th>\n      <td>0.568111</td>\n      <td>0.524390</td>\n      <td>0.546251</td>\n    </tr>\n    <tr>\n      <th>gpt-4-0125-preview</th>\n      <td>0.525573</td>\n      <td>0.502530</td>\n      <td>0.514051</td>\n    </tr>\n    <tr>\n      <th>gpt-4-0314</th>\n      <td>0.494969</td>\n      <td>0.471744</td>\n      <td>0.483357</td>\n    </tr>\n    <tr>\n      <th>claude-1</th>\n      <td>0.443478</td>\n      <td>0.434998</td>\n      <td>0.439238</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>stablelm-tuned-alpha-7b</th>\n      <td>0.175127</td>\n      <td>0.167109</td>\n      <td>0.171118</td>\n    </tr>\n    <tr>\n      <th>llama-13b</th>\n      <td>0.154676</td>\n      <td>0.167286</td>\n      <td>0.160981</td>\n    </tr>\n    <tr>\n      <th>chatglm3-6b</th>\n      <td>0.166998</td>\n      <td>0.150206</td>\n      <td>0.158602</td>\n    </tr>\n    <tr>\n      <th>dolly-v2-12b</th>\n      <td>0.161209</td>\n      <td>0.148883</td>\n      <td>0.155046</td>\n    </tr>\n    <tr>\n      <th>chatglm2-6b</th>\n      <td>0.123675</td>\n      <td>0.135231</td>\n      <td>0.129453</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Preprocess text\ntrain[\"text\"] = train[\"prompt\"].astype(str) + \" \" + train[\"response_a\"].astype(str) + \" \" + train[\"response_b\"].astype(str)\ntest[\"text\"]  = test[\"prompt\"].astype(str)  + \" \" + test[\"response_a\"].astype(str)  + \" \" + test[\"response_b\"].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:22.834512Z","iopub.execute_input":"2025-09-24T03:06:22.834805Z","iopub.status.idle":"2025-09-24T03:06:23.149107Z","shell.execute_reply.started":"2025-09-24T03:06:22.834782Z","shell.execute_reply":"2025-09-24T03:06:23.148285Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Targets\ny = np.argmax(train[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].values, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:23.151351Z","iopub.execute_input":"2025-09-24T03:06:23.151632Z","iopub.status.idle":"2025-09-24T03:06:23.158987Z","shell.execute_reply.started":"2025-09-24T03:06:23.151609Z","shell.execute_reply":"2025-09-24T03:06:23.158250Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Vectorizer\nvectorizer = TfidfVectorizer(\n    max_features=5000,  \n    ngram_range=(1,2),  \n    stop_words=\"english\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:23.160127Z","iopub.execute_input":"2025-09-24T03:06:23.160382Z","iopub.status.idle":"2025-09-24T03:06:23.959694Z","shell.execute_reply.started":"2025-09-24T03:06:23.160363Z","shell.execute_reply":"2025-09-24T03:06:23.958636Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Models\nlog_reg = LogisticRegression(max_iter=2000, class_weight=\"balanced\", C=2.0)\nrf = RandomForestClassifier(n_estimators=300, max_depth=20, n_jobs=-1, random_state=42)\n\nclf = VotingClassifier(\n    estimators=[(\"lr\", log_reg), (\"rf\", rf)],\n    voting=\"soft\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:23.960842Z","iopub.execute_input":"2025-09-24T03:06:23.961771Z","iopub.status.idle":"2025-09-24T03:06:23.983462Z","shell.execute_reply.started":"2025-09-24T03:06:23.961743Z","shell.execute_reply":"2025-09-24T03:06:23.982303Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Train\nX = vectorizer.fit_transform(train[\"text\"])\nclf.fit(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:06:23.984766Z","iopub.execute_input":"2025-09-24T03:06:23.985038Z","iopub.status.idle":"2025-09-24T03:08:59.341109Z","shell.execute_reply.started":"2025-09-24T03:06:23.985014Z","shell.execute_reply":"2025-09-24T03:08:59.340121Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lr',\n                              LogisticRegression(C=2.0, class_weight='balanced',\n                                                 max_iter=2000)),\n                             ('rf',\n                              RandomForestClassifier(max_depth=20,\n                                                     n_estimators=300,\n                                                     n_jobs=-1,\n                                                     random_state=42))],\n                 voting='soft')","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n                              LogisticRegression(C=2.0, class_weight=&#x27;balanced&#x27;,\n                                                 max_iter=2000)),\n                             (&#x27;rf&#x27;,\n                              RandomForestClassifier(max_depth=20,\n                                                     n_estimators=300,\n                                                     n_jobs=-1,\n                                                     random_state=42))],\n                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n                              LogisticRegression(C=2.0, class_weight=&#x27;balanced&#x27;,\n                                                 max_iter=2000)),\n                             (&#x27;rf&#x27;,\n                              RandomForestClassifier(max_depth=20,\n                                                     n_estimators=300,\n                                                     n_jobs=-1,\n                                                     random_state=42))],\n                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2.0, class_weight=&#x27;balanced&#x27;, max_iter=2000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=300, n_jobs=-1,\n                       random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Predict on test\nX_test = vectorizer.transform(test[\"text\"])\nprobs = clf.predict_proba(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:08:59.342261Z","iopub.execute_input":"2025-09-24T03:08:59.342600Z","iopub.status.idle":"2025-09-24T03:08:59.431655Z","shell.execute_reply.started":"2025-09-24T03:08:59.342572Z","shell.execute_reply":"2025-09-24T03:08:59.430802Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Submission\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"winner_model_a\": probs[:,0],\n    \"winner_model_b\": probs[:,1],\n    \"winner_tie\": probs[:,2],\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:08:59.432881Z","iopub.execute_input":"2025-09-24T03:08:59.433367Z","iopub.status.idle":"2025-09-24T03:08:59.439345Z","shell.execute_reply.started":"2025-09-24T03:08:59.433336Z","shell.execute_reply":"2025-09-24T03:08:59.438408Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from IPython.display import display\ndisplay(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:08:59.441781Z","iopub.execute_input":"2025-09-24T03:08:59.442065Z","iopub.status.idle":"2025-09-24T03:08:59.469530Z","shell.execute_reply.started":"2025-09-24T03:08:59.442043Z","shell.execute_reply":"2025-09-24T03:08:59.468385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.243623        0.326923    0.429454\n1   211333        0.318474        0.332797    0.348728\n2  1233961        0.343822        0.420200    0.235978","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.243623</td>\n      <td>0.326923</td>\n      <td>0.429454</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.318474</td>\n      <td>0.332797</td>\n      <td>0.348728</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.343822</td>\n      <td>0.420200</td>\n      <td>0.235978</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created successfully: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:08:59.470570Z","iopub.execute_input":"2025-09-24T03:08:59.470856Z","iopub.status.idle":"2025-09-24T03:08:59.495144Z","shell.execute_reply.started":"2025-09-24T03:08:59.470830Z","shell.execute_reply":"2025-09-24T03:08:59.494163Z"}},"outputs":[{"name":"stdout","text":"Submission file created successfully: submission.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}